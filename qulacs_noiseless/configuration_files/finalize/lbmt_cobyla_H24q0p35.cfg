[general]
episodes = 20000

[env]
num_qubits = 4
num_layers = 40
err_mitig = 0
rand_halt = 0
n_shots = 0
noise_models = 0 
noise_values = 0
fake_min_energy = -1.99009719
fn_type = incremental_with_fixed_ends
accept_err = 1.0160872
shift_threshold_time = 500
shift_threshold_ball = 0.5e-3
success_thresh = 25
succ_radius_shift = 10
succes_switch = 1.0160872
thresholds = []
switch_episodes = []
curriculum_type = MovingThreshold

[problem]
ham_type = H2
geometry = H .0 .0 +.35; H .0 .0 -.35
taper = 1
mapping = jordan_wigner

[agent]
batch_size = 1000
memory_size = 20000
neurons = [1000,1000,1000,1000,1000]
dropout = 0.
learning_rate = 0.0001
angles = 0
en_state = 1
agent_type = DeepQ
agent_class = DQN
init_net = 0
update_target_net = 500
final_gamma = 0.005
epsilon_decay = 0.99995
epsilon_min = 0.05
epsilon_restart = 1.0

[non_local_opt]

a = 1.8658
alpha = 0.9451
c  = 0.046
gamma =0.1397
lamda = 0.0138
beta_1 = 0.9658
beta_2 = 0.8594

maxfev1 = 0
maxfev2 = 0
maxfev3 = 0

maxfev = 1600


global_iters = 1000
method = scipy_each_step
optim_alg = COBYLA

#[non_local_iters]
#LiH 4q 1.2

#maxfev / 3

#1.8958 0.6393 0.0116 0.032  for noiseless

#0.7250 0.5649 0.0516 0.1645 for 1e9 shots

#0.7195 0.5286 0.048 0.1441   for 1e8 shots
#0.9268 0.4936 0.0389 0.1453  for 1e7 shots
#0.6306 0.6821 0.0889 0.0546 for 1e6 shots

#LiH 4q 2.2

#0.9349 0.6169 0.0202 0.1019 for noiseless
#0.725 0.5649 0.0516 0.1645 for 1e9
#0.5471 0.5812 0.0356 0.1443   for 1e8 shots
#0.7909 0.5699 0.0148 0.006  for 1e7 shots
#0.1839 0.304 0.0373 0.0818 for 1e6 shots

#LiH 4q 3.4

#1.6499 0.6819 0.0201 0.0673  for noiseless depth 2.5*4 = 10
#1.7029 0.7035 0.0165 0.0715 for 1e9
#1.6865 0.7101 0.0372 0.0696 for 1e8
#1.707 0.6589 0.0279 0.0692 for 1e7 around 2.2e-3
#1.9943 0.6645 0.0294 0.0665 for 1e6 around 2.2e-3
